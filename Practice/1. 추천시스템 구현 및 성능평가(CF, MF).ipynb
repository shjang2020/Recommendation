{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. í˜‘ì—… í•„í„°ë§ (Collaborative Filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) í˜‘ì—… í•„í„°ë§ì´ë€?\n",
    "- ì‚¬ìš©ì í–‰ë™ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ì•„ì´í…œì„ ì¶”ì²œí•˜ëŠ” ë°©ì‹\n",
    "- ì£¼ì–´ì§„ ë°ì´í„°ê°€ ì‚¬ìš©ì-ì•„ì´í…œ ìƒí˜¸ì‘ìš© ë°ì´í„°(User-Item Interaction Matrix)ì¸ ê²½ìš°\n",
    "\n",
    "2) í˜‘ì—…í•„í„°ë§ì˜ ì¢…ë¥˜\n",
    "- ì‚¬ìš©ì ê¸°ë°˜(User-Based) í˜‘ì—… í•„í„°ë§\n",
    "- ì•„ì´í…œ ê¸°ë°˜(Item-Based) í˜‘ì—… í•„í„°ë§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1. ì‚¬ìš©ì ê¸°ë°˜ í˜‘ì—… í•„í„°ë§ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬:\n",
      "         Item A  Item B  Item C  Item D\n",
      "User 1       5       3       0       1\n",
      "User 2       4       0       4       2\n",
      "User 3       1       1       0       5\n",
      "User 4       0       0       4       4\n",
      "\n",
      "\n",
      "ğŸ”¹ ì‚¬ìš©ì ê°„ ìœ ì‚¬ë„:\n",
      "           User 1    User 2    User 3    User 4\n",
      "User 1  1.000000  0.619780  0.422890  0.119523\n",
      "User 2  0.619780  1.000000  0.449050  0.707107\n",
      "User 3  0.422890  0.449050  1.000000  0.680414\n",
      "User 4  0.119523  0.707107  0.680414  1.000000\n",
      "\n",
      "\n",
      "ğŸ”¹ User 1ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ìš©ì: User 2\n",
      "\n",
      "\n",
      "ğŸ”¹ User 1ì—ê²Œ ì¶”ì²œí•  ì•„ì´í…œ:\n",
      " Item C    4\n",
      "Name: User 2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ì‚¬ìš©ì-ì•„ì´í…œ í‰ì  ë°ì´í„° ìƒì„±\n",
    "ratings = pd.DataFrame([\n",
    "    [5, 3, 0, 1],\n",
    "    [4, 0, 4, 2],\n",
    "    [1, 1, 0, 5],\n",
    "    [0, 0, 4, 4]\n",
    "], index=[\"User 1\", \"User 2\", \"User 3\", \"User 4\"],\n",
    "   columns=[\"Item A\", \"Item B\", \"Item C\", \"Item D\"])\n",
    "\n",
    "print(\"ğŸ”¹ ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬:\\n\", ratings)\n",
    "print(\"\\n\")\n",
    "\n",
    "# ì‚¬ìš©ì ê°„ ìœ ì‚¬ë„ ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)\n",
    "user_similarity = cosine_similarity(ratings.fillna(0))\n",
    "user_sim_df = pd.DataFrame(user_similarity, index=ratings.index, columns=ratings.index)\n",
    "\n",
    "print(\"ğŸ”¹ ì‚¬ìš©ì ê°„ ìœ ì‚¬ë„:\\n\", user_sim_df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# User 1ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ìš©ì ì°¾ê¸°\n",
    "similar_users = user_sim_df[\"User 1\"].sort_values(ascending=False)[1:]\n",
    "print(\"ğŸ”¹ User 1ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ìš©ì:\", similar_users.idxmax())\n",
    "print(\"\\n\")\n",
    "\n",
    "# ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ìš©ìì˜ ì•„ì´í…œ ì¶”ì²œ\n",
    "most_similar_user = similar_users.idxmax()\n",
    "recommended_items = ratings.loc[most_similar_user][ratings.loc[\"User 1\"] == 0].sort_values(ascending=False)\n",
    "print(\"ğŸ”¹ User 1ì—ê²Œ ì¶”ì²œí•  ì•„ì´í…œ:\\n\", recommended_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. ì•„ì´í…œ ê¸°ë°˜ í˜‘ì—… í•„í„°ë§ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ ì•„ì´í…œ ê°„ ìœ ì‚¬ë„:\n",
      "           Item A    Item B    Item C    Item D\n",
      "Item A  1.000000  0.780720  0.436436  0.409514\n",
      "Item B  0.780720  1.000000  0.000000  0.373002\n",
      "Item C  0.436436  0.000000  1.000000  0.625543\n",
      "Item D  0.409514  0.373002  0.625543  1.000000\n",
      "\n",
      "\n",
      "ğŸ”¹ 'Item C'ì™€ ìœ ì‚¬í•œ ì•„ì´í…œ:\n",
      " Item D\n"
     ]
    }
   ],
   "source": [
    "# ì•„ì´í…œ ê°„ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "item_similarity = cosine_similarity(ratings.T.fillna(0))\n",
    "item_sim_df = pd.DataFrame(item_similarity, index=ratings.columns, columns=ratings.columns)\n",
    "\n",
    "print(\"ğŸ”¹ ì•„ì´í…œ ê°„ ìœ ì‚¬ë„:\\n\", item_sim_df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# íŠ¹ì • ì•„ì´í…œê³¼ ìœ ì‚¬í•œ ì•„ì´í…œ ì°¾ê¸°\n",
    "target_item = \"Item C\"\n",
    "similar_items = item_sim_df[target_item].sort_values(ascending=False)[1:]\n",
    "\n",
    "print(f\"ğŸ”¹ '{target_item}'ì™€ ìœ ì‚¬í•œ ì•„ì´í…œ:\\n\", similar_items.idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. í–‰ë ¬ ë¶„í•´(Matrix Factorization) ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) í–‰ë ¬ ë¶„í•´(Matrix Factorization, MF)ë€?\n",
    "- ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬ì„ ì €ì°¨ì› ë²¡í„°ë¡œ ë¶„í•´í•˜ì—¬ ì ì¬ ìš”ì¸(Latent Factors)ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•.\n",
    "\n",
    "âœ… ì£¼ìš” í–‰ë ¬ ë¶„í•´ ì•Œê³ ë¦¬ì¦˜\n",
    "\n",
    "- SVD (Singular Value Decomposition) : ê°€ì¥ ê¸°ë³¸ì ì¸ í–‰ë ¬ ë¶„í•´ ë°©ì‹\n",
    "- NMF (Non-negative Matrix Factorization) : ìŒìˆ˜ê°€ ì—†ëŠ” ë°ì´í„°ì—ì„œ ìœ ìš©\n",
    "- ALS (Alternating Least Squares) : ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥\n",
    "- Deep Learning ê¸°ë°˜ í–‰ë ¬ ë¶„í•´ : ì‹ ê²½ë§ì„ í™œìš©í•œ í™•ì¥ëœ ë°©ë²•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1. SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVD ì¶”ì²œ ë°©ì‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬ (ì˜ˆì œ ë°ì´í„°)\n",
    "R = np.array([\n",
    "    [5, 3, 0, 1],\n",
    "    [4, 0, 0, 1],\n",
    "    [1, 1, 0, 5],\n",
    "    [1, 0, 0, 4],\n",
    "    [0, 1, 5, 4],\n",
    "])\n",
    "\n",
    "# SVD í–‰ë ¬ ë¶„í•´ (2ê°œì˜ ì ì¬ ìš”ì¸ ì‚¬ìš©)\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "U = svd.fit_transform(R)  # ì‚¬ìš©ì ì ì¬ ìš”ì¸ í–‰ë ¬\n",
    "Sigma = np.diag(svd.singular_values_)  # íŠ¹ì´ê°’ í–‰ë ¬\n",
    "V = svd.components_  # ì•„ì´í…œ ì ì¬ ìš”ì¸ í–‰ë ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.94592157,  4.16887476],\n",
       "       [ 2.68400116,  2.76010383],\n",
       "       [ 4.65943967, -0.84914207],\n",
       "       [ 3.61265495, -0.69003845],\n",
       "       [ 4.90266747, -3.55087873]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.03171974, 0.        ],\n",
       "       [0.        , 6.22925557]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47488998,  0.26234348,  0.3005118 ,  0.78444124],\n",
       "       [ 0.78203025,  0.20891356, -0.45754472, -0.36801718]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVD ì¶”ì²œ ì˜ˆì¸¡ í–‰ë ¬ ===\n",
      "[[37.23 14.77 -1.17 18.4 ]\n",
      " [24.96  9.95 -0.58 12.69]\n",
      " [15.85  9.94 15.07 34.96]\n",
      " [12.13  7.66 11.77 27.18]\n",
      " [ 3.73  7.   23.43 42.87]]\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì¸¡ í‰ì  í–‰ë ¬ ë³µì›\n",
    "R_pred = np.dot(np.dot(U, Sigma), V)\n",
    "print(\"=== SVD ì¶”ì²œ ì˜ˆì¸¡ í–‰ë ¬ ===\")\n",
    "print(np.round(R_pred, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.1893  0.9003  1.2347  1.3547  0.6978  0.8753  0.4152  \n",
      "MAE (testset)     0.1619  0.8871  1.2272  1.0344  0.6123  0.7846  0.3705  \n",
      "Fit time          0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.18928193, 0.90025861, 1.23467293, 1.35472279, 0.69778086]),\n",
       " 'test_mae': array([0.16187875, 0.88710515, 1.22716039, 1.03439743, 0.61230039]),\n",
       " 'fit_time': (0.0, 0.0, 0.0, 0.0, 0.0),\n",
       " 'test_time': (0.0, 0.0, 0.0, 0.0, 0.0)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "\n",
    "# ë°ì´í„° ì¤€ë¹„\n",
    "ratings_dict = {\n",
    "    \"userID\": [1, 1, 1, 2, 2, 3, 3, 4, 4, 4],\n",
    "    \"itemID\": [1, 2, 3, 1, 3, 2, 3, 1, 2, 3],\n",
    "    \"rating\": [5, 3, 4, 4, 5, 2, 3, 5, 4, 4]\n",
    "}\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
    "\n",
    "# ë°ì´í„° ë¶„í•  (í›ˆë ¨/í…ŒìŠ¤íŠ¸)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# SVD ëª¨ë¸ í•™ìŠµ\n",
    "model = SVD(n_factors=10, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
    "model.fit(trainset)\n",
    "\n",
    "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# í‰ê°€\n",
    "cross_validate(model, data, cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVDë¥¼ ì‚¬ìš©í•œ íŠ¹ì • ì‚¬ìš©ìì—ê²Œ ì¶”ì²œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ ì‚¬ìš©ì 1ì—ê²Œ ì¶”ì²œí•  ì•„ì´í…œ:\n",
      "ì•„ì´í…œ 1 | ì˜ˆìƒ í‰ì : 4.25\n",
      "ì•„ì´í…œ 3 | ì˜ˆìƒ í‰ì : 4.06\n",
      "ì•„ì´í…œ 2 | ì˜ˆìƒ í‰ì : 3.74\n"
     ]
    }
   ],
   "source": [
    "# íŠ¹ì • ì‚¬ìš©ìì—ê²Œ ì¶”ì²œ ìˆ˜í–‰\n",
    "user_id = 1\n",
    "item_ids = df['itemID'].unique()\n",
    "preds = [model.predict(user_id, iid) for iid in item_ids]\n",
    "\n",
    "# ì˜ˆì¸¡ í‰ì ì´ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "sorted_preds = sorted(preds, key=lambda x:x.est, reverse=True)\n",
    "\n",
    "# ì¶”ì²œ ì•„ì´í…œ ì¶œë ¥\n",
    "print(\"ğŸ”¹ ì‚¬ìš©ì 1ì—ê²Œ ì¶”ì²œí•  ì•„ì´í…œ:\")\n",
    "for pred in sorted_preds:\n",
    "    print(f\"ì•„ì´í…œ {pred.iid} | ì˜ˆìƒ í‰ì : {pred.est:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2. ALS (Alternating Least Squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALSëŠ” êµëŒ€ ìµœì†Œì œê³±ë²•(Alternating Least Squares)ì„ ì´ìš©í•˜ì—¬ ì‚¬ìš©ì í–‰ë ¬ê³¼ ì•„ì´í…œ í–‰ë ¬ì„ ìµœì í™” í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ALS ì¶”ì²œ ë°©ì‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ALS ì¶”ì²œ ì˜ˆì¸¡ í–‰ë ¬ ===\n",
      "[[ 5.13  1.9  -0.72  1.56]\n",
      " [ 3.43  1.28 -0.46  1.09]\n",
      " [ 1.55  1.05  1.79  3.96]\n",
      " [ 1.18  0.8   1.4   3.09]\n",
      " [-0.45  0.54  3.1   5.15]]\n"
     ]
    }
   ],
   "source": [
    "def als_recommendation(R, num_features=2, iterations=10, alpha=0.01):\n",
    "    num_users, num_items = R.shape\n",
    "    U = np.random.rand(num_users, num_features)  # ì‚¬ìš©ì í–‰ë ¬ ì´ˆê¸°í™”\n",
    "    V = np.random.rand(num_items, num_features)  # ì•„ì´í…œ í–‰ë ¬ ì´ˆê¸°í™”\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        # U ì—…ë°ì´íŠ¸: Vë¥¼ ê³ ì •í•˜ê³  ìµœì í™”\n",
    "        for i in range(num_users):\n",
    "            U[i] = np.linalg.solve(np.dot(V.T, V) + alpha * np.eye(num_features), np.dot(V.T, R[i, :].T))\n",
    "\n",
    "        # V ì—…ë°ì´íŠ¸: Uë¥¼ ê³ ì •í•˜ê³  ìµœì í™”\n",
    "        for j in range(num_items):\n",
    "            V[j] = np.linalg.solve(np.dot(U.T, U) + alpha * np.eye(num_features), np.dot(U.T, R[:, j]))\n",
    "\n",
    "    # ì˜ˆì¸¡ í–‰ë ¬ ë³µì›\n",
    "    R_pred = np.dot(U, V.T)\n",
    "    return R_pred\n",
    "\n",
    "# ALS ì¶”ì²œ ê²°ê³¼ ê³„ì‚°\n",
    "R_als_pred = als_recommendation(R)\n",
    "\n",
    "print(\"=== ALS ì¶”ì²œ ì˜ˆì¸¡ í–‰ë ¬ ===\")\n",
    "print(np.round(R_als_pred, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©í•œ ì•”ë¬µì  í”¼ë“œë°± ê¸°ë°˜ ì¶”ì²œ (Implicit ë¼ì´ë¸ŒëŸ¬ë¦¬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seonghyeon\\anaconda3\\envs\\main\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Seonghyeon\\anaconda3\\envs\\main\\Lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: Intel MKL BLAS is configured to use 8 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'MKL_NUM_THREADS=1' or by callng 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having MKL use a threadpool can lead to severe performance issues\n",
      "  check_blas_config()\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 2652.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ ì‚¬ìš©ì 1ì—ê²Œ ì¶”ì²œí•  ì•„ì´í…œ: (array([2, 1, 0]), array([ 3.2506272e-02,  2.7917266e-02, -3.4028235e+38], dtype=float32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "# ğŸ¯ ì‚¬ìš©ì-ì•„ì´í…œ ìƒí˜¸ì‘ìš© ë°ì´í„°\n",
    "user_item_matrix = np.array([\n",
    "    [5, 0, 3, 0, 2],  \n",
    "    [4, 0, 0, 1, 3],  \n",
    "    [1, 1, 0, 5, 0],  \n",
    "    [0, 0, 4, 4, 0]   \n",
    "])\n",
    "\n",
    "# ğŸ¯ í¬ì†Œ í–‰ë ¬ ë³€í™˜\n",
    "sparse_matrix = csr_matrix(user_item_matrix)\n",
    "\n",
    "# ğŸ¯ ALS ëª¨ë¸ í•™ìŠµ\n",
    "als_model = AlternatingLeastSquares(factors=10, regularization=0.1, iterations=20)\n",
    "als_model.fit(sparse_matrix)\n",
    "\n",
    "# ğŸ¯ ì‚¬ìš©ì 1ì—ê²Œ ì¶”ì²œ ìˆ˜í–‰\n",
    "user_id = 1\n",
    "recommendations = als_model.recommend(user_id, sparse_matrix[user_id], N=3)\n",
    "print(\"ğŸ”¹ ì‚¬ìš©ì 1ì—ê²Œ ì¶”ì²œí•  ì•„ì´í…œ:\", recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3. NMF (Non-negative Matrix Factorization) ê¸°ë°˜ ì¶”ì²œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVDëŠ” ìŒìˆ˜ ê°’ì„ í—ˆìš©í•˜ì§€ë§Œ, NMFëŠ” ìŒìˆ˜ë¥¼ í—ˆìš©í•˜ì§€ ì•Šê³  í•´ì„ ê°€ëŠ¥ì„±ì´ ë†’ì€ í–‰ë ¬ ë¶„í•´ ë°©ì‹ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NMF ì¶”ì²œ ë°©ì‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NNMF ì¶”ì²œ ì˜ˆì¸¡ í–‰ë ¬ ===\n",
      "[[5.26 1.99 0.   1.46]\n",
      " [3.5  1.33 0.   0.97]\n",
      " [1.31 0.94 1.95 3.95]\n",
      " [0.98 0.72 1.53 3.08]\n",
      " [0.   0.65 2.84 5.22]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# NNMF ëª¨ë¸ ì ìš© (2ê°œì˜ ì ì¬ ìš”ì¸ ì‚¬ìš©)\n",
    "nmf = NMF(n_components=2, init='random', random_state=42)\n",
    "U_nnmf = nmf.fit_transform(R)  # ì‚¬ìš©ì ì ì¬ ìš”ì¸ í–‰ë ¬\n",
    "V_nnmf = nmf.components_  # ì•„ì´í…œ ì ì¬ ìš”ì¸ í–‰ë ¬\n",
    "\n",
    "# ì˜ˆì¸¡ í–‰ë ¬ ë³µì›\n",
    "R_nnmf_pred = np.dot(U_nnmf, V_nnmf)\n",
    "\n",
    "print(\"=== NNMF ì¶”ì²œ ì˜ˆì¸¡ í–‰ë ¬ ===\")\n",
    "print(np.round(R_nnmf_pred, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NMF on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.3832  0.9014  1.4583  2.0487  0.5627  1.2709  0.5081  \n",
      "MAE (testset)     1.2868  0.7500  1.4570  1.9025  0.4546  1.1702  0.5140  \n",
      "Fit time          0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.38320264, 0.90138782, 1.45830882, 2.04874654, 0.56274335]),\n",
       " 'test_mae': array([1.28683208, 0.75      , 1.45700357, 1.90252556, 0.45459099]),\n",
       " 'fit_time': (0.0, 0.0, 0.0, 0.0, 0.001039743423461914),\n",
       " 'test_time': (0.0, 0.0, 0.0, 0.0, 0.0)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from surprise import NMF\n",
    "\n",
    "# NMF ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
    "nmf_model = NMF(n_factors=10, n_epochs=20)\n",
    "nmf_model.fit(trainset)\n",
    "\n",
    "# í‰ê°€\n",
    "cross_validate(nmf_model, data, cv=5, verbose=True)\n",
    "\n",
    "# âœ… NMFëŠ” ìŒìˆ˜ ê°’ì„ í—ˆìš©í•˜ì§€ ì•Šì•„ í•´ì„ ê°€ëŠ¥ì„±ì´ ë†’ìŒ.\n",
    "# âœ… SVDë³´ë‹¤ ê²°ê³¼ í•´ì„ì´ ìš©ì´í•˜ì§€ë§Œ, ë°ì´í„° íŠ¹ì„±ì— ë”°ë¼ ì„±ëŠ¥ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ì„±ëŠ¥ í‰ê°€ ë° ëª¨ë¸ ë¹„êµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ“Œ ì¶”ì²œ ì‹œìŠ¤í…œ í‰ê°€ ì§€í‘œ\n",
    "- RMSE (Root Mean Squared Error) : ì˜ˆì¸¡ í‰ì ê³¼ ì‹¤ì œ í‰ì  ê°„ì˜ ì°¨ì´\n",
    "- Precision@K : ì¶”ì²œí•œ ì•„ì´í…œ ì¤‘ ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ì†Œë¹„í•œ ì•„ì´í…œ ë¹„ìœ¨\n",
    "- Recall@K : ì‚¬ìš©ìê°€ ì†Œë¹„í•œ ì•„ì´í…œ ì¤‘ ì¶”ì²œí•œ ì•„ì´í…œ ë¹„ìœ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8517\n",
      "ğŸ”¹ RMSE: 0.8517\n"
     ]
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"ğŸ”¹ RMSE: {rmse:.4f}\")\n",
    "\n",
    "# âœ… RMSE ê°’ì´ ì‘ì„ìˆ˜ë¡ ì¶”ì²œ ì„±ëŠ¥ì´ ì¢‹ìŒ.\n",
    "# âœ… Precision@K, Recall@Kë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ í‰ê°€ ê°€ëŠ¥."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cf) Pytorch ê¸°ë°˜ ì‚¬ìš©ì-ì•„ì´í…œ í˜‘ì—… í•„í„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ì‚¬ìš©ì-ì•„ì´í…œ í‰ì  ë°ì´í„°\n",
    "ratings = np.array([\n",
    "    [1,1,5],\n",
    "    [1,2,3],\n",
    "    [2,1,4],\n",
    "    [2,3,5],\n",
    "    [3,2,2],\n",
    "    [3,3,3],\n",
    "    [4,1,5],\n",
    "    [4,2,4]\n",
    "])\n",
    "\n",
    "# Pytorch Dataset ìƒì„±\n",
    "class RatingDataset(Dataset):\n",
    "    def __init__(self, ratings):\n",
    "        self.users = torch.tensor(ratings[:,0]-1, dtype=torch.long) # ì‚¬ìš©ì ID (0ë¶€í„° ì‹œì‘)\n",
    "        self.items = torch.tensor(ratings[:,1]-1, dtype=torch.long) # ì•„ì´í…œí…œ ID (0ë¶€í„° ì‹œì‘)\n",
    "        self.ratings = torch.tensor(ratings[:,2], dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
    "\n",
    "dataset = RatingDataset(ratings)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 19.4707\n",
      "Epoch 2, Loss: 17.6865\n",
      "Epoch 3, Loss: 25.6540\n",
      "Epoch 4, Loss: 16.0960\n",
      "Epoch 5, Loss: 29.6430\n",
      "Epoch 6, Loss: 4.2679\n",
      "Epoch 7, Loss: 19.5744\n",
      "Epoch 8, Loss: 18.5817\n",
      "Epoch 9, Loss: 16.1084\n",
      "Epoch 10, Loss: 15.1465\n"
     ]
    }
   ],
   "source": [
    "# Pytorch í˜‘ì—… í•„í„°ë§ ëª¨ë¸ ì •ì˜\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim = 10):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        user_embedded = self.user_embedding(user)\n",
    "        item_embedded = self.item_embedding(item)\n",
    "        return (user_embedded * item_embedded).sum(1)\n",
    "\n",
    "# ì‚¬ìš©ì ìˆ˜ì™€ ì•„ì´í…œ ìˆ˜ ê³„ì‚°\n",
    "num_users = int(ratings[:, 0].max())\n",
    "num_items = int(ratings[:, 1].max())\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = MatrixFactorization(num_users, num_items)\n",
    "\n",
    "# ğŸ¯ 4ï¸âƒ£ ëª¨ë¸ í•™ìŠµ\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for users, items, ratings in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(users, items)\n",
    "        loss = criterion(outputs, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš©ì 1ì´ ì•„ì´í…œ 2ì— ëŒ€í•œ ì˜ˆìƒ í‰ì : 2.79\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ 5ï¸âƒ£ ì¶”ì²œ ì˜ˆì¸¡\n",
    "user_id = torch.tensor([0])\n",
    "item_id = torch.tensor([1])\n",
    "predicted_rating = model(user_id, item_id).item()\n",
    "print(f\"ì‚¬ìš©ì 1ì´ ì•„ì´í…œ 2ì— ëŒ€í•œ ì˜ˆìƒ í‰ì : {predicted_rating:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
