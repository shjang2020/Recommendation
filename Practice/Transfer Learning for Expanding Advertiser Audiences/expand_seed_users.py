# 7. expand_seed_users.py - ê´‘ê³ ì£¼ê°€ ë“¤ì–´ì™”ì„ ë•Œ í›„ë³´êµ° ì¶”ì¶œ
# CLI ì¸ì(seed_ids, top_k ë“±) ìˆ˜ì‹ 
# AnnoyIndex ë¡œë“œ -> per-seed & mean-vector ê¸°ë°˜ í›„ë³´ ì¶”ì¶œ
# AnnoyIndexê°€ ì—†ëŠ” ê²½ìš° Cosine fallback
# optionalë¡œ seed_to_cands.npyì— ì €ì¥
# LSHë¡œ í›„ë³´êµ°ì„ ì„ ë³„

"""
expand_seed_users.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1) ì‚¬ìš©ì ì„ë² ë”©  : embed.py â†’ data/user_embeddings.parquet
   â”œâ”€ user_id
   â””â”€ dim_0 â€¦ dim_31 (L2-norm)
   
2) Annoy ì¸ë±ìŠ¤   : build_ann_index.py â†’ data/annoy_user.idx
   â””â”€ .idmap.npy  : idx â†” user_id ë§¤í•‘

3) í›„ë³´êµ° ì €ì¥    : --pairs_out ì˜µì…˜ ì‚¬ìš© ì‹œ
   numpy .npy (pickle) { "<seed_ids>": [candidate_id, â€¦] }

ì‚¬ìš© ì˜ˆ)
$ python expand_seed_users.py \
        --top_k 200 \
        --index_path data/annoy_user.idx \
        --search_k 1000 \
        --pairs_out data/seed_to_cands.npy
"""

import argparse, os
from pathlib import Path
import pandas as pd
import numpy as np
from annoy import AnnoyIndex
import pyarrow.parquet as pq
from sklearn.metrics.pairwise import cosine_similarity     # fallback ìš©

# ---------- Annoy ìœ í‹¸ --------------------------------------------
def load_annoy(index_path: str, embed_path: str):
    schema = pq.read_schema(embed_path)
    dim = len(schema) - 1

    idmap = np.load(Path(index_path).with_suffix(".idmap.npy"))
    ann = AnnoyIndex(dim, 'angular')
    ann.load(index_path)
    return ann, idmap

def get_candidates_annoy(ann, idmap, seed_ids, top_k, search_k):
    """Annoy ê¸°ë°˜ í›„ë³´êµ° ì¶”ì¶œ (seed ê°œë³„ + í‰ê· ë²¡í„°)"""
    seed_idx = []
    for sid in seed_ids:
        idx_arr = np.where(idmap == sid)[0]
        if len(idx_arr) == 0:
            raise ValueError(f"seed_id {sid}ëŠ” ì¸ë±ìŠ¤ì— ì—†ìŠµë‹ˆë‹¤.")
        seed_idx.append(int(idx_arr[0]))
    # 1. ê° seed ê°œë³„ ì´ì›ƒ top-k ì¶”ì¶œ
    neighbor_sets = [ann.get_nns_by_item(i, top_k, search_k=search_k) for i in seed_idx]
    # 2. seed í‰ê·  ë²¡í„°ì˜ ì´ì›ƒ
    mean_vec = np.mean([ann.get_item_vector(i) for i in seed_idx], axis=0) # seed ë²¡í„°ë“¤ì˜ í‰ê· 
    mean_cand = ann.get_nns_by_vector(mean_vec.tolist(), top_k, search_k=search_k) # í‰ê· ë²¡í„° ê¸°ì¤€ ì´ì›ƒ top-k ì¶”ì¶œ
    # 3. ì¸ë±ìŠ¤ ì§‘í•©(ë²ˆí˜¸ ì¤‘ë³µ ì œê±°, ì‹œë“œ ì¸ë±ìŠ¤ ì œì™¸)
    cand_idx = set(mean_cand).union(*neighbor_sets) - set(seed_idx)
    # 4. ë²ˆí˜¸ â†’ user_id ë§¤í•‘
    cand_uids = idmap[list(cand_idx)]
    # 5. user_id ê¸°ì¤€ ì¤‘ë³µ ì œê±° + ì‹œë“œ ì œê±° + ìˆœì„œ ê³ ì •
    seen = set(seed_ids)    # ì‹œë“œëŠ” ë¯¸ë¦¬ ë„£ì–´ ì œì™¸
    rec_ids_unique = []
    for uid in cand_uids:
        if uid not in seen:
            seen.add(uid)
            rec_ids_unique.append(uid)
        if len(rec_ids_unique) >= top_k:   # early stop
            break
    return rec_ids_unique  # list[int] ê¸¸ì´ â‰¤ top_k

# ---------- ê¸°ì¡´ Cosine fallback ----------------------------------
def load_embeddings(path: str) -> pd.DataFrame:
    return pd.read_parquet(path) if path.endswith(".parquet") else pd.read_csv(path)

def recommend_cosine(seed_ids, top_k, emb_path):
    df = load_embeddings(emb_path)
    seed_vecs = df[df["user_id"].isin(seed_ids)].drop(columns=["user_id"]).values
    seed_mean = np.mean(seed_vecs, axis=0, keepdims=True)
    sims = cosine_similarity(seed_mean, df.drop(columns=["user_id"]).values).flatten()
    result = (pd.DataFrame({"user_id": df["user_id"], "sim": sims})
                .query("user_id not in @seed_ids")
                .sort_values("sim", ascending=False)
                .head(top_k))
    return result["user_id"].values

# ---------- main ---------------------------------------------------
def main():
    parser = argparse.ArgumentParser("Seed user ê¸°ë°˜ í›„ë³´êµ° ì¶”ì¶œ (Annoy + Cosine fallback)")
    parser.add_argument("seed_ids", nargs="+", type=int, help="seed user id ë¦¬ìŠ¤íŠ¸")
    parser.add_argument("--top_k", type=int, default=100, help="í›„ë³´êµ° í¬ê¸°")
    parser.add_argument("--index_path", type=str, default="data/annoy_user.idx", help="Annoy .idx ê²½ë¡œ")
    parser.add_argument("--search_k", type=int, default=-1, help="Annoy search_k (ê¸°ë³¸ n_trees*10)")
    parser.add_argument("--embedding_path", type=str, default="data/user_embeddings.parquet",
                        help="ì½”ì‚¬ì¸ fallback ì‹œ ì„ë² ë”© ê²½ë¡œ")
    parser.add_argument("--pairs_out", type=str, default="data/seed_to_cands.npy",
                        help="í›„ë³´êµ° ë”•ì…”ë„ˆë¦¬ë¥¼ .npy ë¡œ ì €ì¥")
    args = parser.parse_args()

    if args.index_path and Path(args.index_path).exists():
        ann, idmap = load_annoy(args.index_path, embed_path=args.embedding_path)
        if args.search_k == -1:
            args.search_k = ann.get_n_trees() * 10
        rec_ids = get_candidates_annoy(ann, idmap, args.seed_ids, args.top_k, args.search_k)
        print(f"ğŸ“Œ Annoy ê²°ê³¼ Top-{args.top_k}  (search_k={args.search_k})")
    else:
        rec_ids = recommend_cosine(args.seed_ids, args.top_k, args.embedding_path)
        print(f"ğŸ“Œ Cosine(fallback) ê²°ê³¼ Top-{args.top_k}")
    print(rec_ids)
    
    # â”€â”€ í›„ë³´êµ° ì €ì¥
    if args.pairs_out:
        Path(args.pairs_out).parent.mkdir(parents=True, exist_ok=True)
        if os.path.exists(args.pairs_out):
            mapping = np.load(args.pairs_out, allow_pickle=True).item()
        else:
            mapping = {}
        mapping[str(args.seed_ids)] = rec_ids
        np.save(args.pairs_out, mapping)
        print(f"ğŸ’¾ pairs saved â†’ {args.pairs_out}")

if __name__ == "__main__":
    main()